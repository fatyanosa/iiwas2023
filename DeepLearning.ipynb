{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "1. Read the dataset.\n",
    "2. Reshape the dataset\n",
    "2. Split the dataset to:\n",
    "    * 70% training (only contain normal data),\n",
    "    * 10% validation (contain normal and anomaly data), and\n",
    "    * 20% testing dataset (contain normal and anomaly data)\n",
    "3. Create autoencoder model.\n",
    "4. Train the model using training dataset.\n",
    "5. Validate the model using validation dataset.\n",
    "6. Test the model using testing dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "value_range = (0, 40000)\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 17\n",
    "\n",
    "# Define model's hyperparameters\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomaly(df, label='anomaly', plot_item='value', time_col='timestamp'):\n",
    "    # Create sections\n",
    "    sections = list()\n",
    "    state = df.iloc[0][label]\n",
    "    start = 0\n",
    "    for i in df.index:\n",
    "        if df.loc[i][label] != state:\n",
    "            state = df.loc[i][label]\n",
    "            sections.append(df.loc[start:i].copy(deep=True))\n",
    "            start = i\n",
    "    sections.append(df.loc[start:].copy(deep=True))\n",
    "\n",
    "    # Plot sections\n",
    "    plt.close()\n",
    "    plt.figure().set_figwidth(20)\n",
    "    for s in sections:\n",
    "        # Change index\n",
    "        s.index = s[time_col]\n",
    "\n",
    "        color = 'blue' if s.iloc[0][label] == 0 else 'red'\n",
    "        # plt.plot(s.index, s[plot_item], color=color)\n",
    "        plt.scatter(s.index, s[plot_item], color=color)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cm(cm):\n",
    "    plt.close()\n",
    "    # plt.figure(figsize=(8,8))\n",
    "    # sns.set(font_scale = 1.5)\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        cm, # confusion matrix 2D array \n",
    "        annot=True, # show numbers in the cells\n",
    "        fmt='d', # show numbers as integers\n",
    "        xticklabels=[0,1],\n",
    "        yticklabels=[0,1],\n",
    "        # cbar=False, # don't show the color bar\n",
    "        # cmap='flag', # customize color map\n",
    "        # vmin=200, # to get better color contrast\n",
    "        # vmax=800 # to get better color contrast\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def show_matrix(y, y_pred):\n",
    "    ps = precision_score(y, y_pred, pos_label=1, labels=[0, 1])\n",
    "    print(\"precision_score: %.2f\" % ps)\n",
    "\n",
    "    rs = recall_score(y, y_pred, pos_label=1, labels=[0, 1])\n",
    "    print(\"recall_score: %.2f\" % rs)\n",
    "\n",
    "    f1 = f1_score(y, y_pred, pos_label=1, labels=[0, 1])\n",
    "    print(\"f1_score: %.2f\" % f1)\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred, labels=[0, 1])\n",
    "    # print(\"conf_matrix\")\n",
    "    # print(cm)\n",
    "    plot_cm(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "raw = pd.read_csv('/nas.dbms/mahendra.data/Documents/annotation/NAB/data/realKnownCause/nyc_taxi.csv',low_memory=False)\n",
    "raw['timestamp'] = pd.to_datetime(raw['timestamp'])\n",
    "\n",
    "\n",
    "# The times of anomaly events (Ground Truth)\n",
    "anomaly_points = [\n",
    "        [\n",
    "            \"2014-10-30 15:30:00.000000\",\n",
    "            \"2014-11-03 22:30:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2014-11-25 12:00:00.000000\",\n",
    "            \"2014-11-29 19:00:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2014-12-23 11:30:00.000000\",\n",
    "            \"2014-12-27 18:30:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2014-12-29 21:30:00.000000\",\n",
    "            \"2015-01-03 04:30:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2015-01-24 20:30:00.000000\",\n",
    "            \"2015-01-29 03:30:00.000000\"\n",
    "        ]\n",
    "]\n",
    "\n",
    "# Normal label: 0, Anomaly label: 1\n",
    "raw['anomaly'] = 0  # Set default values\n",
    "for start, end in anomaly_points:\n",
    "    raw.loc[((raw['timestamp'] >= start) & (raw['timestamp'] <= end)), 'anomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  value  anomaly\n",
      "0 2014-07-01 00:00:00  10844        0\n",
      "1 2014-07-01 00:30:00   8127        0\n",
      "2 2014-07-01 01:00:00   6210        0\n",
      "3 2014-07-01 01:30:00   4656        0\n",
      "4 2014-07-01 02:00:00   3820        0\n",
      "\n",
      "Dataset size:\n",
      "(10320, 3)\n",
      "\n",
      "Dataset distribution:\n",
      "0    9285\n",
      "1    1035\n",
      "Name: anomaly, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(raw.head())\n",
    "print(\"\\nDataset size:\")\n",
    "print(raw.shape)\n",
    "print(\"\\nDataset distribution:\")\n",
    "print(raw['anomaly'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = int(raw.shape[0]/window_size)\n",
    "col = window_size\n",
    "\n",
    "# Convert from pandas to numpy\n",
    "X = raw['value'].to_numpy()\n",
    "y = raw['anomaly'].to_numpy()\n",
    "\n",
    "# Reshape\n",
    "X = X.reshape((row, col))\n",
    "y = y.reshape((row, col))\n",
    "\n",
    "\n",
    "# Normalization\n",
    "X = (X - value_range[0]) / (value_range[1] - value_range[0])\n",
    "\n",
    "# Calculate the median of the labels\n",
    "y = np.round(np.mean(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset\n",
      "X shape: (412, 20)\n",
      "y shape: (412,)\n",
      "Anomaly distribution:\n",
      "0.0    375\n",
      "1.0     37\n",
      "dtype: int64\n",
      "\n",
      "Testing dataset\n",
      "X shape: (104, 20)\n",
      "y shape: (104,)\n",
      "Anomaly distribution:\n",
      "0.0    91\n",
      "1.0    13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state,)\n",
    "\n",
    "print(\"Training dataset\")\n",
    "print(\"X shape:\", X_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "print(\"Anomaly distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "print(\"\\nTesting dataset\")\n",
    "print(\"X shape:\", X_test.shape)\n",
    "print(\"y shape:\", y_test.shape)\n",
    "print(\"Anomaly distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.5935802459716797\n",
      "Epoch [2/1000], Loss: 0.496896356344223\n",
      "Epoch [3/1000], Loss: 0.3996390104293823\n",
      "Epoch [4/1000], Loss: 0.39538663625717163\n",
      "Epoch [5/1000], Loss: 0.19008378684520721\n",
      "Epoch [6/1000], Loss: 0.24340897798538208\n",
      "Epoch [7/1000], Loss: 0.2669123709201813\n",
      "Epoch [8/1000], Loss: 0.6136177778244019\n",
      "Epoch [9/1000], Loss: 0.4925663471221924\n",
      "Epoch [10/1000], Loss: 0.293771892786026\n",
      "Epoch [11/1000], Loss: 0.316824734210968\n",
      "Epoch [12/1000], Loss: 0.44114238023757935\n",
      "Epoch [13/1000], Loss: 0.2951200008392334\n",
      "Epoch [14/1000], Loss: 0.265038400888443\n",
      "Epoch [15/1000], Loss: 0.2594638764858246\n",
      "Epoch [16/1000], Loss: 0.15076909959316254\n",
      "Epoch [17/1000], Loss: 0.3913519084453583\n",
      "Epoch [18/1000], Loss: 0.579633891582489\n",
      "Epoch [19/1000], Loss: 0.3099765479564667\n",
      "Epoch [20/1000], Loss: 0.303015798330307\n",
      "Epoch [21/1000], Loss: 0.22865068912506104\n",
      "Epoch [22/1000], Loss: 0.4782108664512634\n",
      "Epoch [23/1000], Loss: 0.23525211215019226\n",
      "Epoch [24/1000], Loss: 0.19496795535087585\n",
      "Epoch [25/1000], Loss: 0.28491806983947754\n",
      "Epoch [26/1000], Loss: 0.17842553555965424\n",
      "Epoch [27/1000], Loss: 0.16693156957626343\n",
      "Epoch [28/1000], Loss: 0.18168920278549194\n",
      "Epoch [29/1000], Loss: 0.16013702750205994\n",
      "Epoch [30/1000], Loss: 0.36645039916038513\n",
      "Epoch [31/1000], Loss: 0.3502679765224457\n",
      "Epoch [32/1000], Loss: 0.36854860186576843\n",
      "Epoch [33/1000], Loss: 0.26717668771743774\n",
      "Epoch [34/1000], Loss: 0.23306246101856232\n",
      "Epoch [35/1000], Loss: 0.21560832858085632\n",
      "Epoch [36/1000], Loss: 0.1694430410861969\n",
      "Epoch [37/1000], Loss: 0.41343817114830017\n",
      "Epoch [38/1000], Loss: 0.2184562087059021\n",
      "Epoch [39/1000], Loss: 0.5263016819953918\n",
      "Epoch [40/1000], Loss: 0.39811772108078003\n",
      "Epoch [41/1000], Loss: 0.25479644536972046\n",
      "Epoch [42/1000], Loss: 0.3156222403049469\n",
      "Epoch [43/1000], Loss: 0.3557552397251129\n",
      "Epoch [44/1000], Loss: 0.3163355588912964\n",
      "Epoch [45/1000], Loss: 0.19631652534008026\n",
      "Epoch [46/1000], Loss: 0.4312700033187866\n",
      "Epoch [47/1000], Loss: 0.13292738795280457\n",
      "Epoch [48/1000], Loss: 0.2575756311416626\n",
      "Epoch [49/1000], Loss: 0.4119865596294403\n",
      "Epoch [50/1000], Loss: 0.40056487917900085\n",
      "Epoch [51/1000], Loss: 0.3429848849773407\n",
      "Epoch [52/1000], Loss: 0.29914769530296326\n",
      "Epoch [53/1000], Loss: 0.16744202375411987\n",
      "Epoch [54/1000], Loss: 0.3786945939064026\n",
      "Epoch [55/1000], Loss: 0.25470423698425293\n",
      "Epoch [56/1000], Loss: 0.3018859624862671\n",
      "Epoch [57/1000], Loss: 0.31129083037376404\n",
      "Epoch [58/1000], Loss: 0.27286702394485474\n",
      "Epoch [59/1000], Loss: 0.16429124772548676\n",
      "Epoch [60/1000], Loss: 0.3477749228477478\n",
      "Epoch [61/1000], Loss: 0.5123769044876099\n",
      "Epoch [62/1000], Loss: 0.2518576979637146\n",
      "Epoch [63/1000], Loss: 0.34378230571746826\n",
      "Epoch [64/1000], Loss: 0.1903192102909088\n",
      "Epoch [65/1000], Loss: 0.21365980803966522\n",
      "Epoch [66/1000], Loss: 0.30948206782341003\n",
      "Epoch [67/1000], Loss: 0.3185059130191803\n",
      "Epoch [68/1000], Loss: 0.39214441180229187\n",
      "Epoch [69/1000], Loss: 0.1371648609638214\n",
      "Epoch [70/1000], Loss: 0.4470401704311371\n",
      "Epoch [71/1000], Loss: 0.09890346974134445\n",
      "Epoch [72/1000], Loss: 0.07446122169494629\n",
      "Epoch [73/1000], Loss: 0.46875935792922974\n",
      "Epoch [74/1000], Loss: 0.17266219854354858\n",
      "Epoch [75/1000], Loss: 0.22417345643043518\n",
      "Epoch [76/1000], Loss: 0.08993551880121231\n",
      "Epoch [77/1000], Loss: 0.18522658944129944\n",
      "Epoch [78/1000], Loss: 0.5931165218353271\n",
      "Epoch [79/1000], Loss: 0.24362888932228088\n",
      "Epoch [80/1000], Loss: 0.40734899044036865\n",
      "Epoch [81/1000], Loss: 0.21579763293266296\n",
      "Epoch [82/1000], Loss: 0.22444278001785278\n",
      "Epoch [83/1000], Loss: 0.5130565166473389\n",
      "Epoch [84/1000], Loss: 0.23652417957782745\n",
      "Epoch [85/1000], Loss: 0.20652124285697937\n",
      "Epoch [86/1000], Loss: 0.23370185494422913\n",
      "Epoch [87/1000], Loss: 0.19108977913856506\n",
      "Epoch [88/1000], Loss: 0.19385682046413422\n",
      "Epoch [89/1000], Loss: 0.4192740023136139\n",
      "Epoch [90/1000], Loss: 0.2336336076259613\n",
      "Epoch [91/1000], Loss: 0.22775150835514069\n",
      "Epoch [92/1000], Loss: 0.5008888244628906\n",
      "Epoch [93/1000], Loss: 0.1985684484243393\n",
      "Epoch [94/1000], Loss: 0.26742833852767944\n",
      "Epoch [95/1000], Loss: 0.20978495478630066\n",
      "Epoch [96/1000], Loss: 0.2365788221359253\n",
      "Epoch [97/1000], Loss: 0.120211161673069\n",
      "Epoch [98/1000], Loss: 0.34469157457351685\n",
      "Epoch [99/1000], Loss: 0.1797078251838684\n",
      "Epoch [100/1000], Loss: 0.23605994880199432\n",
      "Epoch [101/1000], Loss: 0.23757053911685944\n",
      "Epoch [102/1000], Loss: 0.10099205374717712\n",
      "Epoch [103/1000], Loss: 0.18494902551174164\n",
      "Epoch [104/1000], Loss: 0.25099876523017883\n",
      "Epoch [105/1000], Loss: 0.1363997459411621\n",
      "Epoch [106/1000], Loss: 0.10557108372449875\n",
      "Epoch [107/1000], Loss: 0.22988490760326385\n",
      "Epoch [108/1000], Loss: 0.45367711782455444\n",
      "Epoch [109/1000], Loss: 0.25572070479393005\n",
      "Epoch [110/1000], Loss: 0.4430587589740753\n",
      "Epoch [111/1000], Loss: 0.1452333629131317\n",
      "Epoch [112/1000], Loss: 0.14146696031093597\n",
      "Epoch [113/1000], Loss: 0.34305498003959656\n",
      "Epoch [114/1000], Loss: 0.20257064700126648\n",
      "Epoch [115/1000], Loss: 0.38113364577293396\n",
      "Epoch [116/1000], Loss: 0.15880003571510315\n",
      "Epoch [117/1000], Loss: 0.3168313503265381\n",
      "Epoch [118/1000], Loss: 0.34539052844047546\n",
      "Epoch [119/1000], Loss: 0.21266968548297882\n",
      "Epoch [120/1000], Loss: 0.362520307302475\n",
      "Epoch [121/1000], Loss: 0.3436356782913208\n",
      "Epoch [122/1000], Loss: 0.3511882722377777\n",
      "Epoch [123/1000], Loss: 0.270126074552536\n",
      "Epoch [124/1000], Loss: 0.19194141030311584\n",
      "Epoch [125/1000], Loss: 0.2528330981731415\n",
      "Epoch [126/1000], Loss: 0.08809234946966171\n",
      "Epoch [127/1000], Loss: 0.3849133849143982\n",
      "Epoch [128/1000], Loss: 0.3901410400867462\n",
      "Epoch [129/1000], Loss: 0.1714249700307846\n",
      "Epoch [130/1000], Loss: 0.46673282980918884\n",
      "Epoch [131/1000], Loss: 0.17127171158790588\n",
      "Epoch [132/1000], Loss: 0.2483135461807251\n",
      "Epoch [133/1000], Loss: 0.23066012561321259\n",
      "Epoch [134/1000], Loss: 0.2637295424938202\n",
      "Epoch [135/1000], Loss: 0.3115902841091156\n",
      "Epoch [136/1000], Loss: 0.07790204882621765\n",
      "Epoch [137/1000], Loss: 0.2775568664073944\n",
      "Epoch [138/1000], Loss: 0.18443892896175385\n",
      "Epoch [139/1000], Loss: 0.15653392672538757\n",
      "Epoch [140/1000], Loss: 0.40953266620635986\n",
      "Epoch [141/1000], Loss: 0.3065218925476074\n",
      "Epoch [142/1000], Loss: 0.3533789813518524\n",
      "Epoch [143/1000], Loss: 0.25606387853622437\n",
      "Epoch [144/1000], Loss: 0.4035683870315552\n",
      "Epoch [145/1000], Loss: 0.25850170850753784\n",
      "Epoch [146/1000], Loss: 0.16948547959327698\n",
      "Epoch [147/1000], Loss: 0.3577466905117035\n",
      "Epoch [148/1000], Loss: 0.3824057877063751\n",
      "Epoch [149/1000], Loss: 0.3282584249973297\n",
      "Epoch [150/1000], Loss: 0.7657865881919861\n",
      "Epoch [151/1000], Loss: 0.24095523357391357\n",
      "Epoch [152/1000], Loss: 0.42747360467910767\n",
      "Epoch [153/1000], Loss: 0.21514779329299927\n",
      "Epoch [154/1000], Loss: 0.4481797516345978\n",
      "Epoch [155/1000], Loss: 0.15032844245433807\n",
      "Epoch [156/1000], Loss: 0.181749165058136\n",
      "Epoch [157/1000], Loss: 0.1478559970855713\n",
      "Epoch [158/1000], Loss: 0.2806330621242523\n",
      "Epoch [159/1000], Loss: 0.17512330412864685\n",
      "Epoch [160/1000], Loss: 0.3425864577293396\n",
      "Epoch [161/1000], Loss: 0.20587369799613953\n",
      "Epoch [162/1000], Loss: 0.09348190575838089\n",
      "Epoch [163/1000], Loss: 0.18601128458976746\n",
      "Epoch [164/1000], Loss: 0.35560697317123413\n",
      "Epoch [165/1000], Loss: 0.22429722547531128\n",
      "Epoch [166/1000], Loss: 0.16817183792591095\n",
      "Epoch [167/1000], Loss: 0.31416428089141846\n",
      "Epoch [168/1000], Loss: 0.36353543400764465\n",
      "Epoch [169/1000], Loss: 0.16701802611351013\n",
      "Epoch [170/1000], Loss: 0.24367305636405945\n",
      "Epoch [171/1000], Loss: 0.1105799451470375\n",
      "Epoch [172/1000], Loss: 0.17193695902824402\n",
      "Epoch [173/1000], Loss: 0.17284196615219116\n",
      "Epoch [174/1000], Loss: 0.26534757018089294\n",
      "Epoch [175/1000], Loss: 0.07279827445745468\n",
      "Epoch [176/1000], Loss: 0.21529118716716766\n",
      "Epoch [177/1000], Loss: 0.1902369111776352\n",
      "Epoch [178/1000], Loss: 0.2726742923259735\n",
      "Epoch [179/1000], Loss: 0.4316588342189789\n",
      "Epoch [180/1000], Loss: 0.1036854088306427\n",
      "Epoch [181/1000], Loss: 0.5186559557914734\n",
      "Epoch [182/1000], Loss: 0.3411525785923004\n",
      "Epoch [183/1000], Loss: 0.24416406452655792\n",
      "Epoch [184/1000], Loss: 0.3557668924331665\n",
      "Epoch [185/1000], Loss: 0.4044448435306549\n",
      "Epoch [186/1000], Loss: 0.0776045024394989\n",
      "Epoch [187/1000], Loss: 0.24783875048160553\n",
      "Epoch [188/1000], Loss: 0.346730500459671\n",
      "Epoch [189/1000], Loss: 0.17681798338890076\n",
      "Epoch [190/1000], Loss: 0.24490058422088623\n",
      "Epoch [191/1000], Loss: 0.3894186317920685\n",
      "Epoch [192/1000], Loss: 0.17058151960372925\n",
      "Epoch [193/1000], Loss: 0.24884814023971558\n",
      "Epoch [194/1000], Loss: 0.22108116745948792\n",
      "Epoch [195/1000], Loss: 0.39302876591682434\n",
      "Epoch [196/1000], Loss: 0.4000155031681061\n",
      "Epoch [197/1000], Loss: 0.21439863741397858\n",
      "Epoch [198/1000], Loss: 0.24133417010307312\n",
      "Epoch [199/1000], Loss: 0.1542167365550995\n",
      "Epoch [200/1000], Loss: 0.13905975222587585\n",
      "Epoch [201/1000], Loss: 0.13787540793418884\n",
      "Epoch [202/1000], Loss: 0.1728239804506302\n",
      "Epoch [203/1000], Loss: 0.36016222834587097\n",
      "Epoch [204/1000], Loss: 0.2862815856933594\n",
      "Epoch [205/1000], Loss: 0.08364487439393997\n",
      "Epoch [206/1000], Loss: 0.06707416474819183\n",
      "Epoch [207/1000], Loss: 0.287802517414093\n",
      "Epoch [208/1000], Loss: 0.3150673806667328\n",
      "Epoch [209/1000], Loss: 0.25625595450401306\n",
      "Epoch [210/1000], Loss: 0.23080182075500488\n",
      "Epoch [211/1000], Loss: 0.12434431910514832\n",
      "Epoch [212/1000], Loss: 0.3222907781600952\n",
      "Epoch [213/1000], Loss: 0.2919773757457733\n",
      "Epoch [214/1000], Loss: 0.1730991154909134\n",
      "Epoch [215/1000], Loss: 0.40644362568855286\n",
      "Epoch [216/1000], Loss: 0.27440550923347473\n",
      "Epoch [217/1000], Loss: 0.16117477416992188\n",
      "Epoch [218/1000], Loss: 0.4315989017486572\n",
      "Epoch [219/1000], Loss: 0.1412496417760849\n",
      "Epoch [220/1000], Loss: 0.300668329000473\n",
      "Epoch [221/1000], Loss: 0.3063926100730896\n",
      "Epoch [222/1000], Loss: 0.09973039478063583\n",
      "Epoch [223/1000], Loss: 0.3633309304714203\n",
      "Epoch [224/1000], Loss: 0.17966271936893463\n",
      "Epoch [225/1000], Loss: 0.36551764607429504\n",
      "Epoch [226/1000], Loss: 0.2232946753501892\n",
      "Epoch [227/1000], Loss: 0.07189824432134628\n",
      "Epoch [228/1000], Loss: 0.3343746066093445\n",
      "Epoch [229/1000], Loss: 0.29489463567733765\n",
      "Epoch [230/1000], Loss: 0.3307602107524872\n",
      "Epoch [231/1000], Loss: 0.44345730543136597\n",
      "Epoch [232/1000], Loss: 0.5023048520088196\n",
      "Epoch [233/1000], Loss: 0.10796715319156647\n",
      "Epoch [234/1000], Loss: 0.1844756156206131\n",
      "Epoch [235/1000], Loss: 0.39584773778915405\n",
      "Epoch [236/1000], Loss: 0.28250133991241455\n",
      "Epoch [237/1000], Loss: 0.3300479054450989\n",
      "Epoch [238/1000], Loss: 0.20110735297203064\n",
      "Epoch [239/1000], Loss: 0.28235456347465515\n",
      "Epoch [240/1000], Loss: 0.2743951380252838\n",
      "Epoch [241/1000], Loss: 0.18440216779708862\n",
      "Epoch [242/1000], Loss: 0.26685163378715515\n",
      "Epoch [243/1000], Loss: 0.3956478238105774\n",
      "Epoch [244/1000], Loss: 0.4185100495815277\n",
      "Epoch [245/1000], Loss: 0.43037328124046326\n",
      "Epoch [246/1000], Loss: 0.2714184522628784\n",
      "Epoch [247/1000], Loss: 0.15643110871315002\n",
      "Epoch [248/1000], Loss: 0.45041194558143616\n",
      "Epoch [249/1000], Loss: 0.21638190746307373\n",
      "Epoch [250/1000], Loss: 0.19215045869350433\n",
      "Epoch [251/1000], Loss: 0.2605496346950531\n",
      "Epoch [252/1000], Loss: 0.3567015528678894\n",
      "Epoch [253/1000], Loss: 0.07829689979553223\n",
      "Epoch [254/1000], Loss: 0.19080521166324615\n",
      "Epoch [255/1000], Loss: 0.16678279638290405\n",
      "Epoch [256/1000], Loss: 0.11113773286342621\n",
      "Epoch [257/1000], Loss: 0.17484551668167114\n",
      "Epoch [258/1000], Loss: 0.40485721826553345\n",
      "Epoch [259/1000], Loss: 0.33781686425209045\n",
      "Epoch [260/1000], Loss: 0.22695378959178925\n",
      "Epoch [261/1000], Loss: 0.48090460896492004\n",
      "Epoch [262/1000], Loss: 0.09339325875043869\n",
      "Epoch [263/1000], Loss: 0.3125336766242981\n",
      "Epoch [264/1000], Loss: 0.27013203501701355\n",
      "Epoch [265/1000], Loss: 0.3169200122356415\n",
      "Epoch [266/1000], Loss: 0.22899730503559113\n",
      "Epoch [267/1000], Loss: 0.181512251496315\n",
      "Epoch [268/1000], Loss: 0.16514292359352112\n",
      "Epoch [269/1000], Loss: 0.1300307959318161\n",
      "Epoch [270/1000], Loss: 0.17518804967403412\n",
      "Epoch [271/1000], Loss: 0.2694390118122101\n",
      "Epoch [272/1000], Loss: 0.2843540608882904\n",
      "Epoch [273/1000], Loss: 0.24892546236515045\n",
      "Epoch [274/1000], Loss: 0.3573775589466095\n",
      "Epoch [275/1000], Loss: 0.1608409434556961\n",
      "Epoch [276/1000], Loss: 0.09851480275392532\n",
      "Epoch [277/1000], Loss: 0.23880304396152496\n",
      "Epoch [278/1000], Loss: 0.2266673594713211\n",
      "Epoch [279/1000], Loss: 0.2725735306739807\n",
      "Epoch [280/1000], Loss: 0.10261999815702438\n",
      "Epoch [281/1000], Loss: 0.23881514370441437\n",
      "Epoch [282/1000], Loss: 0.18534725904464722\n",
      "Epoch [283/1000], Loss: 0.20737774670124054\n",
      "Epoch [284/1000], Loss: 0.2502782940864563\n",
      "Epoch [285/1000], Loss: 0.225375235080719\n",
      "Epoch [286/1000], Loss: 0.1958901733160019\n",
      "Epoch [287/1000], Loss: 0.3267192840576172\n",
      "Epoch [288/1000], Loss: 0.1728799045085907\n",
      "Epoch [289/1000], Loss: 0.3209744095802307\n",
      "Epoch [290/1000], Loss: 0.1740218549966812\n",
      "Epoch [291/1000], Loss: 0.2773241400718689\n",
      "Epoch [292/1000], Loss: 0.15687958896160126\n",
      "Epoch [293/1000], Loss: 0.15035860240459442\n",
      "Epoch [294/1000], Loss: 0.41825830936431885\n",
      "Epoch [295/1000], Loss: 0.4690561592578888\n",
      "Epoch [296/1000], Loss: 0.3547133207321167\n",
      "Epoch [297/1000], Loss: 0.39558684825897217\n",
      "Epoch [298/1000], Loss: 0.37024691700935364\n",
      "Epoch [299/1000], Loss: 0.3712342381477356\n",
      "Epoch [300/1000], Loss: 0.1449017971754074\n",
      "Epoch [301/1000], Loss: 0.17675703763961792\n",
      "Epoch [302/1000], Loss: 0.10281733423471451\n",
      "Epoch [303/1000], Loss: 0.24256888031959534\n",
      "Epoch [304/1000], Loss: 0.25425028800964355\n",
      "Epoch [305/1000], Loss: 0.15910130739212036\n",
      "Epoch [306/1000], Loss: 0.41127637028694153\n",
      "Epoch [307/1000], Loss: 0.2383946180343628\n",
      "Epoch [308/1000], Loss: 0.10013116151094437\n",
      "Epoch [309/1000], Loss: 0.13675646483898163\n",
      "Epoch [310/1000], Loss: 0.2571946978569031\n",
      "Epoch [311/1000], Loss: 0.16053397953510284\n",
      "Epoch [312/1000], Loss: 0.07934067398309708\n",
      "Epoch [313/1000], Loss: 0.23740386962890625\n",
      "Epoch [314/1000], Loss: 0.1311863511800766\n",
      "Epoch [315/1000], Loss: 0.059209682047367096\n",
      "Epoch [316/1000], Loss: 0.25221380591392517\n",
      "Epoch [317/1000], Loss: 0.41648069024086\n",
      "Epoch [318/1000], Loss: 0.3272174894809723\n",
      "Epoch [319/1000], Loss: 0.35658541321754456\n",
      "Epoch [320/1000], Loss: 0.0715889260172844\n",
      "Epoch [321/1000], Loss: 0.3560808300971985\n",
      "Epoch [322/1000], Loss: 0.2626744210720062\n",
      "Epoch [323/1000], Loss: 0.24707505106925964\n",
      "Epoch [324/1000], Loss: 0.20031197369098663\n",
      "Epoch [325/1000], Loss: 0.08883707970380783\n",
      "Epoch [326/1000], Loss: 0.27210456132888794\n",
      "Epoch [327/1000], Loss: 0.2107851654291153\n",
      "Epoch [328/1000], Loss: 0.3916442096233368\n",
      "Epoch [329/1000], Loss: 0.23441298305988312\n",
      "Epoch [330/1000], Loss: 0.17620597779750824\n",
      "Epoch [331/1000], Loss: 0.14327746629714966\n",
      "Epoch [332/1000], Loss: 0.3301745355129242\n",
      "Epoch [333/1000], Loss: 0.2537826895713806\n",
      "Epoch [334/1000], Loss: 0.21071888506412506\n",
      "Epoch [335/1000], Loss: 0.27978578209877014\n",
      "Epoch [336/1000], Loss: 0.26677340269088745\n",
      "Epoch [337/1000], Loss: 0.34086188673973083\n",
      "Epoch [338/1000], Loss: 0.3861906826496124\n",
      "Epoch [339/1000], Loss: 0.5328391790390015\n",
      "Epoch [340/1000], Loss: 0.2095167487859726\n",
      "Epoch [341/1000], Loss: 0.22617286443710327\n",
      "Epoch [342/1000], Loss: 0.17084449529647827\n",
      "Epoch [343/1000], Loss: 0.29794710874557495\n",
      "Epoch [344/1000], Loss: 0.23249274492263794\n",
      "Epoch [345/1000], Loss: 0.5670716762542725\n",
      "Epoch [346/1000], Loss: 0.22592763602733612\n",
      "Epoch [347/1000], Loss: 0.24077101051807404\n",
      "Epoch [348/1000], Loss: 0.14765605330467224\n",
      "Epoch [349/1000], Loss: 0.2557287812232971\n",
      "Epoch [350/1000], Loss: 0.23588617146015167\n",
      "Epoch [351/1000], Loss: 0.0864831730723381\n",
      "Epoch [352/1000], Loss: 0.16651371121406555\n",
      "Epoch [353/1000], Loss: 0.3236243426799774\n",
      "Epoch [354/1000], Loss: 0.32163044810295105\n",
      "Epoch [355/1000], Loss: 0.16242572665214539\n",
      "Epoch [356/1000], Loss: 0.08578432351350784\n",
      "Epoch [357/1000], Loss: 0.16734196245670319\n",
      "Epoch [358/1000], Loss: 0.19493988156318665\n",
      "Epoch [359/1000], Loss: 0.3904319107532501\n",
      "Epoch [360/1000], Loss: 0.09283172339200974\n",
      "Epoch [361/1000], Loss: 0.36282986402511597\n",
      "Epoch [362/1000], Loss: 0.39235302805900574\n",
      "Epoch [363/1000], Loss: 0.28059452772140503\n",
      "Epoch [364/1000], Loss: 0.3001371920108795\n",
      "Epoch [365/1000], Loss: 0.18515799939632416\n",
      "Epoch [366/1000], Loss: 0.07836399227380753\n",
      "Epoch [367/1000], Loss: 0.33692556619644165\n",
      "Epoch [368/1000], Loss: 0.28779149055480957\n",
      "Epoch [369/1000], Loss: 0.24229279160499573\n",
      "Epoch [370/1000], Loss: 0.20359259843826294\n",
      "Epoch [371/1000], Loss: 0.24241280555725098\n",
      "Epoch [372/1000], Loss: 0.15576475858688354\n",
      "Epoch [373/1000], Loss: 0.22128194570541382\n",
      "Epoch [374/1000], Loss: 0.16235502064228058\n",
      "Epoch [375/1000], Loss: 0.06687120348215103\n",
      "Epoch [376/1000], Loss: 0.2778392434120178\n",
      "Epoch [377/1000], Loss: 0.20586280524730682\n",
      "Epoch [378/1000], Loss: 0.22540149092674255\n",
      "Epoch [379/1000], Loss: 0.4165925085544586\n",
      "Epoch [380/1000], Loss: 0.10419594496488571\n",
      "Epoch [381/1000], Loss: 0.2758677899837494\n",
      "Epoch [382/1000], Loss: 0.18816451728343964\n",
      "Epoch [383/1000], Loss: 0.4239134192466736\n",
      "Epoch [384/1000], Loss: 0.442295640707016\n",
      "Epoch [385/1000], Loss: 0.3451574444770813\n",
      "Epoch [386/1000], Loss: 0.1760890930891037\n",
      "Epoch [387/1000], Loss: 0.2162315398454666\n",
      "Epoch [388/1000], Loss: 0.14654813706874847\n",
      "Epoch [389/1000], Loss: 0.07035335153341293\n",
      "Epoch [390/1000], Loss: 0.2700444161891937\n",
      "Epoch [391/1000], Loss: 0.32065439224243164\n",
      "Epoch [392/1000], Loss: 0.43822693824768066\n",
      "Epoch [393/1000], Loss: 0.1930820196866989\n",
      "Epoch [394/1000], Loss: 0.08710095286369324\n",
      "Epoch [395/1000], Loss: 0.27814021706581116\n",
      "Epoch [396/1000], Loss: 0.3141545057296753\n",
      "Epoch [397/1000], Loss: 0.3975525498390198\n",
      "Epoch [398/1000], Loss: 0.1914689987897873\n",
      "Epoch [399/1000], Loss: 0.35456612706184387\n",
      "Epoch [400/1000], Loss: 0.23804907500743866\n",
      "Epoch [401/1000], Loss: 0.05916569009423256\n",
      "Epoch [402/1000], Loss: 0.2096630185842514\n",
      "Epoch [403/1000], Loss: 0.14625689387321472\n",
      "Epoch [404/1000], Loss: 0.21137672662734985\n",
      "Epoch [405/1000], Loss: 0.16116073727607727\n",
      "Epoch [406/1000], Loss: 0.2826327979564667\n",
      "Epoch [407/1000], Loss: 0.07813373953104019\n",
      "Epoch [408/1000], Loss: 0.15187588334083557\n",
      "Epoch [409/1000], Loss: 0.4178061783313751\n",
      "Epoch [410/1000], Loss: 0.21597035229206085\n",
      "Epoch [411/1000], Loss: 0.21076610684394836\n",
      "Epoch [412/1000], Loss: 0.2023594081401825\n",
      "Epoch [413/1000], Loss: 0.2500587999820709\n",
      "Epoch [414/1000], Loss: 0.22629381716251373\n",
      "Epoch [415/1000], Loss: 0.32392221689224243\n",
      "Epoch [416/1000], Loss: 0.15331421792507172\n",
      "Epoch [417/1000], Loss: 0.24591150879859924\n",
      "Epoch [418/1000], Loss: 0.21749457716941833\n",
      "Epoch [419/1000], Loss: 0.3926708400249481\n",
      "Epoch [420/1000], Loss: 0.18130439519882202\n",
      "Epoch [421/1000], Loss: 0.2444712370634079\n",
      "Epoch [422/1000], Loss: 0.22585931420326233\n",
      "Epoch [423/1000], Loss: 0.08010232448577881\n",
      "Epoch [424/1000], Loss: 0.2080533653497696\n",
      "Epoch [425/1000], Loss: 0.14838600158691406\n",
      "Epoch [426/1000], Loss: 0.2334776371717453\n",
      "Epoch [427/1000], Loss: 0.2424568384885788\n",
      "Epoch [428/1000], Loss: 0.1752289980649948\n",
      "Epoch [429/1000], Loss: 0.4209519028663635\n",
      "Epoch [430/1000], Loss: 0.17637449502944946\n",
      "Epoch [431/1000], Loss: 0.2026422917842865\n",
      "Epoch [432/1000], Loss: 0.28457948565483093\n",
      "Epoch [433/1000], Loss: 0.24927309155464172\n",
      "Epoch [434/1000], Loss: 0.10847968608140945\n",
      "Epoch [435/1000], Loss: 0.3523207902908325\n",
      "Epoch [436/1000], Loss: 0.2130005955696106\n",
      "Epoch [437/1000], Loss: 0.30553922057151794\n",
      "Epoch [438/1000], Loss: 0.1010683923959732\n",
      "Epoch [439/1000], Loss: 0.2871462106704712\n",
      "Epoch [440/1000], Loss: 0.23538820445537567\n",
      "Epoch [441/1000], Loss: 0.2936055362224579\n",
      "Epoch [442/1000], Loss: 0.13832740485668182\n",
      "Epoch [443/1000], Loss: 0.34472283720970154\n",
      "Epoch [444/1000], Loss: 0.3009718954563141\n",
      "Epoch [445/1000], Loss: 0.22838535904884338\n",
      "Epoch [446/1000], Loss: 0.4171280562877655\n",
      "Epoch [447/1000], Loss: 0.1540079563856125\n",
      "Epoch [448/1000], Loss: 0.0620030052959919\n",
      "Epoch [449/1000], Loss: 0.2731572389602661\n",
      "Epoch [450/1000], Loss: 0.2079155147075653\n",
      "Epoch [451/1000], Loss: 0.3023028075695038\n",
      "Epoch [452/1000], Loss: 0.20482316613197327\n",
      "Epoch [453/1000], Loss: 0.2687847316265106\n",
      "Epoch [454/1000], Loss: 0.33263862133026123\n",
      "Epoch [455/1000], Loss: 0.119407519698143\n",
      "Epoch [456/1000], Loss: 0.327111154794693\n",
      "Epoch [457/1000], Loss: 0.25515514612197876\n",
      "Epoch [458/1000], Loss: 0.3057516813278198\n",
      "Epoch [459/1000], Loss: 0.3242393434047699\n",
      "Epoch [460/1000], Loss: 0.17155958712100983\n",
      "Epoch [461/1000], Loss: 0.1275348663330078\n",
      "Epoch [462/1000], Loss: 0.164214089512825\n",
      "Epoch [463/1000], Loss: 0.2300725132226944\n",
      "Epoch [464/1000], Loss: 0.16193535923957825\n",
      "Epoch [465/1000], Loss: 0.22598019242286682\n",
      "Epoch [466/1000], Loss: 0.19774959981441498\n",
      "Epoch [467/1000], Loss: 0.11193150281906128\n",
      "Epoch [468/1000], Loss: 0.33246561884880066\n",
      "Epoch [469/1000], Loss: 0.2002255618572235\n",
      "Epoch [470/1000], Loss: 0.18288861215114594\n",
      "Epoch [471/1000], Loss: 0.18327729403972626\n",
      "Epoch [472/1000], Loss: 0.14925873279571533\n",
      "Epoch [473/1000], Loss: 0.05411199480295181\n",
      "Epoch [474/1000], Loss: 0.26179003715515137\n",
      "Epoch [475/1000], Loss: 0.2785111367702484\n",
      "Epoch [476/1000], Loss: 0.11178970336914062\n",
      "Epoch [477/1000], Loss: 0.3279561698436737\n",
      "Epoch [478/1000], Loss: 0.11040600389242172\n",
      "Epoch [479/1000], Loss: 0.09928763657808304\n",
      "Epoch [480/1000], Loss: 0.12978893518447876\n",
      "Epoch [481/1000], Loss: 0.21540455520153046\n",
      "Epoch [482/1000], Loss: 0.09261377155780792\n",
      "Epoch [483/1000], Loss: 0.07589363306760788\n",
      "Epoch [484/1000], Loss: 0.2429923713207245\n",
      "Epoch [485/1000], Loss: 0.4100923240184784\n",
      "Epoch [486/1000], Loss: 0.1672188937664032\n",
      "Epoch [487/1000], Loss: 0.30648747086524963\n",
      "Epoch [488/1000], Loss: 0.1456851363182068\n",
      "Epoch [489/1000], Loss: 0.11575786769390106\n",
      "Epoch [490/1000], Loss: 0.3562885820865631\n",
      "Epoch [491/1000], Loss: 0.4141048192977905\n",
      "Epoch [492/1000], Loss: 0.31642672419548035\n",
      "Epoch [493/1000], Loss: 0.23457588255405426\n",
      "Epoch [494/1000], Loss: 0.29606887698173523\n",
      "Epoch [495/1000], Loss: 0.16482415795326233\n",
      "Epoch [496/1000], Loss: 0.18143683671951294\n",
      "Epoch [497/1000], Loss: 0.11893392354249954\n",
      "Epoch [498/1000], Loss: 0.3823074698448181\n",
      "Epoch [499/1000], Loss: 0.3303315341472626\n",
      "Epoch [500/1000], Loss: 0.39802083373069763\n",
      "Epoch [501/1000], Loss: 0.15418143570423126\n",
      "Epoch [502/1000], Loss: 0.30238696932792664\n",
      "Epoch [503/1000], Loss: 0.21984615921974182\n",
      "Epoch [504/1000], Loss: 0.23317937552928925\n",
      "Epoch [505/1000], Loss: 0.25843995809555054\n",
      "Epoch [506/1000], Loss: 0.0822841227054596\n",
      "Epoch [507/1000], Loss: 0.34896567463874817\n",
      "Epoch [508/1000], Loss: 0.22642748057842255\n",
      "Epoch [509/1000], Loss: 0.2316407412290573\n",
      "Epoch [510/1000], Loss: 0.4145526587963104\n",
      "Epoch [511/1000], Loss: 0.21242405474185944\n",
      "Epoch [512/1000], Loss: 0.3337746262550354\n",
      "Epoch [513/1000], Loss: 0.23178258538246155\n",
      "Epoch [514/1000], Loss: 0.32987087965011597\n",
      "Epoch [515/1000], Loss: 0.2927430272102356\n",
      "Epoch [516/1000], Loss: 0.36780279874801636\n",
      "Epoch [517/1000], Loss: 0.1332891285419464\n",
      "Epoch [518/1000], Loss: 0.1558644026517868\n",
      "Epoch [519/1000], Loss: 0.2721173167228699\n",
      "Epoch [520/1000], Loss: 0.1631801873445511\n",
      "Epoch [521/1000], Loss: 0.1617032289505005\n",
      "Epoch [522/1000], Loss: 0.286963552236557\n",
      "Epoch [523/1000], Loss: 0.16430440545082092\n",
      "Epoch [524/1000], Loss: 0.13786883652210236\n",
      "Epoch [525/1000], Loss: 0.20184296369552612\n",
      "Epoch [526/1000], Loss: 0.09964852780103683\n",
      "Epoch [527/1000], Loss: 0.5831770300865173\n",
      "Epoch [528/1000], Loss: 0.20379389822483063\n",
      "Epoch [529/1000], Loss: 0.21694187819957733\n",
      "Epoch [530/1000], Loss: 0.3562585413455963\n",
      "Epoch [531/1000], Loss: 0.3430705964565277\n",
      "Epoch [532/1000], Loss: 0.25887519121170044\n",
      "Epoch [533/1000], Loss: 0.2327302098274231\n",
      "Epoch [534/1000], Loss: 0.37621834874153137\n",
      "Epoch [535/1000], Loss: 0.1230706200003624\n",
      "Epoch [536/1000], Loss: 0.19205240905284882\n",
      "Epoch [537/1000], Loss: 0.15327736735343933\n",
      "Epoch [538/1000], Loss: 0.20064674317836761\n",
      "Epoch [539/1000], Loss: 0.24259202182292938\n",
      "Epoch [540/1000], Loss: 0.30736133456230164\n",
      "Epoch [541/1000], Loss: 0.22853460907936096\n",
      "Epoch [542/1000], Loss: 0.16735056042671204\n",
      "Epoch [543/1000], Loss: 0.19646352529525757\n",
      "Epoch [544/1000], Loss: 0.13015638291835785\n",
      "Epoch [545/1000], Loss: 0.14905747771263123\n",
      "Epoch [546/1000], Loss: 0.0949842557311058\n",
      "Epoch [547/1000], Loss: 0.12970302999019623\n",
      "Epoch [548/1000], Loss: 0.1326214075088501\n",
      "Epoch [549/1000], Loss: 0.39109018445014954\n",
      "Epoch [550/1000], Loss: 0.2502613961696625\n",
      "Epoch [551/1000], Loss: 0.2530161738395691\n",
      "Epoch [552/1000], Loss: 0.3998979926109314\n",
      "Epoch [553/1000], Loss: 0.12044624984264374\n",
      "Epoch [554/1000], Loss: 0.26523950695991516\n",
      "Epoch [555/1000], Loss: 0.18949922919273376\n",
      "Epoch [556/1000], Loss: 0.0860058143734932\n",
      "Epoch [557/1000], Loss: 0.2355802208185196\n",
      "Epoch [558/1000], Loss: 0.11469460278749466\n",
      "Epoch [559/1000], Loss: 0.19998498260974884\n",
      "Epoch [560/1000], Loss: 0.10653753578662872\n",
      "Epoch [561/1000], Loss: 0.13138508796691895\n",
      "Epoch [562/1000], Loss: 0.4244321584701538\n",
      "Epoch [563/1000], Loss: 0.2712572515010834\n",
      "Epoch [564/1000], Loss: 0.26110705733299255\n",
      "Epoch [565/1000], Loss: 0.2572985887527466\n",
      "Epoch [566/1000], Loss: 0.23557057976722717\n",
      "Epoch [567/1000], Loss: 0.13357602059841156\n",
      "Epoch [568/1000], Loss: 0.22425800561904907\n",
      "Epoch [569/1000], Loss: 0.24577400088310242\n",
      "Epoch [570/1000], Loss: 0.30746427178382874\n",
      "Epoch [571/1000], Loss: 0.2504579722881317\n",
      "Epoch [572/1000], Loss: 0.10710526257753372\n",
      "Epoch [573/1000], Loss: 0.3470038175582886\n",
      "Epoch [574/1000], Loss: 0.15119154751300812\n",
      "Epoch [575/1000], Loss: 0.36257827281951904\n",
      "Epoch [576/1000], Loss: 0.36533841490745544\n",
      "Epoch [577/1000], Loss: 0.06960645318031311\n",
      "Epoch [578/1000], Loss: 0.3453579843044281\n",
      "Epoch [579/1000], Loss: 0.24300983548164368\n",
      "Epoch [580/1000], Loss: 0.3143991529941559\n",
      "Epoch [581/1000], Loss: 0.2582223117351532\n",
      "Epoch [582/1000], Loss: 0.16306760907173157\n",
      "Epoch [583/1000], Loss: 0.16427679359912872\n",
      "Epoch [584/1000], Loss: 0.2500443458557129\n",
      "Epoch [585/1000], Loss: 0.19964276254177094\n",
      "Epoch [586/1000], Loss: 0.2760126292705536\n",
      "Epoch [587/1000], Loss: 0.23082049190998077\n",
      "Epoch [588/1000], Loss: 0.1794610619544983\n",
      "Epoch [589/1000], Loss: 0.10521066933870316\n",
      "Epoch [590/1000], Loss: 0.2859116792678833\n",
      "Epoch [591/1000], Loss: 0.19987522065639496\n",
      "Epoch [592/1000], Loss: 0.21416760981082916\n",
      "Epoch [593/1000], Loss: 0.3026353120803833\n",
      "Epoch [594/1000], Loss: 0.1567145437002182\n",
      "Epoch [595/1000], Loss: 0.3137274384498596\n",
      "Epoch [596/1000], Loss: 0.3842189908027649\n",
      "Epoch [597/1000], Loss: 0.4834240972995758\n",
      "Epoch [598/1000], Loss: 0.06887512654066086\n",
      "Epoch [599/1000], Loss: 0.5133459568023682\n",
      "Epoch [600/1000], Loss: 0.5038036704063416\n",
      "Epoch [601/1000], Loss: 0.20302201807498932\n",
      "Epoch [602/1000], Loss: 0.15055817365646362\n",
      "Epoch [603/1000], Loss: 0.37637460231781006\n",
      "Epoch [604/1000], Loss: 0.226333349943161\n",
      "Epoch [605/1000], Loss: 0.13474249839782715\n",
      "Epoch [606/1000], Loss: 0.26811885833740234\n",
      "Epoch [607/1000], Loss: 0.23126059770584106\n",
      "Epoch [608/1000], Loss: 0.21261802315711975\n",
      "Epoch [609/1000], Loss: 0.25333189964294434\n",
      "Epoch [610/1000], Loss: 0.16717003285884857\n",
      "Epoch [611/1000], Loss: 0.26637375354766846\n",
      "Epoch [612/1000], Loss: 0.07880021631717682\n",
      "Epoch [613/1000], Loss: 0.20381902158260345\n",
      "Epoch [614/1000], Loss: 0.36307206749916077\n",
      "Epoch [615/1000], Loss: 0.33460932970046997\n",
      "Epoch [616/1000], Loss: 0.24959100782871246\n",
      "Epoch [617/1000], Loss: 0.18841472268104553\n",
      "Epoch [618/1000], Loss: 0.2460053414106369\n",
      "Epoch [619/1000], Loss: 0.2470974326133728\n",
      "Epoch [620/1000], Loss: 0.20277906954288483\n",
      "Epoch [621/1000], Loss: 0.15813720226287842\n",
      "Epoch [622/1000], Loss: 0.24531437456607819\n",
      "Epoch [623/1000], Loss: 0.405036985874176\n",
      "Epoch [624/1000], Loss: 0.1259501576423645\n",
      "Epoch [625/1000], Loss: 0.2822844684123993\n",
      "Epoch [626/1000], Loss: 0.24014084041118622\n",
      "Epoch [627/1000], Loss: 0.07546615600585938\n",
      "Epoch [628/1000], Loss: 0.38131198287010193\n",
      "Epoch [629/1000], Loss: 0.13710644841194153\n",
      "Epoch [630/1000], Loss: 0.256256103515625\n",
      "Epoch [631/1000], Loss: 0.37687623500823975\n",
      "Epoch [632/1000], Loss: 0.17318138480186462\n",
      "Epoch [633/1000], Loss: 0.15246005356311798\n",
      "Epoch [634/1000], Loss: 0.1775713860988617\n",
      "Epoch [635/1000], Loss: 0.20575763285160065\n",
      "Epoch [636/1000], Loss: 0.06385058164596558\n",
      "Epoch [637/1000], Loss: 0.34690147638320923\n",
      "Epoch [638/1000], Loss: 0.22700954973697662\n",
      "Epoch [639/1000], Loss: 0.19780796766281128\n",
      "Epoch [640/1000], Loss: 0.10560227930545807\n",
      "Epoch [641/1000], Loss: 0.3239161968231201\n",
      "Epoch [642/1000], Loss: 0.16465765237808228\n",
      "Epoch [643/1000], Loss: 0.33178845047950745\n",
      "Epoch [644/1000], Loss: 0.058297935873270035\n",
      "Epoch [645/1000], Loss: 0.1778770089149475\n",
      "Epoch [646/1000], Loss: 0.10632971674203873\n",
      "Epoch [647/1000], Loss: 0.1786828637123108\n",
      "Epoch [648/1000], Loss: 0.412209153175354\n",
      "Epoch [649/1000], Loss: 0.24858863651752472\n",
      "Epoch [650/1000], Loss: 0.1289946436882019\n",
      "Epoch [651/1000], Loss: 0.10720856487751007\n",
      "Epoch [652/1000], Loss: 0.4415290951728821\n",
      "Epoch [653/1000], Loss: 0.31374770402908325\n",
      "Epoch [654/1000], Loss: 0.38592153787612915\n",
      "Epoch [655/1000], Loss: 0.2790704071521759\n",
      "Epoch [656/1000], Loss: 0.26228663325309753\n",
      "Epoch [657/1000], Loss: 0.12192292511463165\n",
      "Epoch [658/1000], Loss: 0.06411543488502502\n",
      "Epoch [659/1000], Loss: 0.2515389621257782\n",
      "Epoch [660/1000], Loss: 0.20584219694137573\n",
      "Epoch [661/1000], Loss: 0.17746157944202423\n",
      "Epoch [662/1000], Loss: 0.21401581168174744\n",
      "Epoch [663/1000], Loss: 0.1562274992465973\n",
      "Epoch [664/1000], Loss: 0.23182496428489685\n",
      "Epoch [665/1000], Loss: 0.21799249947071075\n",
      "Epoch [666/1000], Loss: 0.2595936357975006\n",
      "Epoch [667/1000], Loss: 0.2763559818267822\n",
      "Epoch [668/1000], Loss: 0.3043050467967987\n",
      "Epoch [669/1000], Loss: 0.2655939757823944\n",
      "Epoch [670/1000], Loss: 0.25322067737579346\n",
      "Epoch [671/1000], Loss: 0.11502150446176529\n",
      "Epoch [672/1000], Loss: 0.2833060622215271\n",
      "Epoch [673/1000], Loss: 0.11170284450054169\n",
      "Epoch [674/1000], Loss: 0.14548969268798828\n",
      "Epoch [675/1000], Loss: 0.34440308809280396\n",
      "Epoch [676/1000], Loss: 0.1682434380054474\n",
      "Epoch [677/1000], Loss: 0.264270544052124\n",
      "Epoch [678/1000], Loss: 0.281350314617157\n",
      "Epoch [679/1000], Loss: 0.22309501469135284\n",
      "Epoch [680/1000], Loss: 0.16727346181869507\n",
      "Epoch [681/1000], Loss: 0.07337019592523575\n",
      "Epoch [682/1000], Loss: 0.12915635108947754\n",
      "Epoch [683/1000], Loss: 0.07569824159145355\n",
      "Epoch [684/1000], Loss: 0.23883658647537231\n",
      "Epoch [685/1000], Loss: 0.38941580057144165\n",
      "Epoch [686/1000], Loss: 0.19382712244987488\n",
      "Epoch [687/1000], Loss: 0.3384345471858978\n",
      "Epoch [688/1000], Loss: 0.15042279660701752\n",
      "Epoch [689/1000], Loss: 0.20388679206371307\n",
      "Epoch [690/1000], Loss: 0.07288096100091934\n",
      "Epoch [691/1000], Loss: 0.11088721454143524\n",
      "Epoch [692/1000], Loss: 0.3751521706581116\n",
      "Epoch [693/1000], Loss: 0.12468311190605164\n",
      "Epoch [694/1000], Loss: 0.4097018837928772\n",
      "Epoch [695/1000], Loss: 0.07037986814975739\n",
      "Epoch [696/1000], Loss: 0.3041156828403473\n",
      "Epoch [697/1000], Loss: 0.4407004415988922\n",
      "Epoch [698/1000], Loss: 0.13613951206207275\n",
      "Epoch [699/1000], Loss: 0.10830937325954437\n",
      "Epoch [700/1000], Loss: 0.06714322417974472\n",
      "Epoch [701/1000], Loss: 0.14133211970329285\n",
      "Epoch [702/1000], Loss: 0.20545583963394165\n",
      "Epoch [703/1000], Loss: 0.4374959468841553\n",
      "Epoch [704/1000], Loss: 0.12606191635131836\n",
      "Epoch [705/1000], Loss: 0.0824447050690651\n",
      "Epoch [706/1000], Loss: 0.30488091707229614\n",
      "Epoch [707/1000], Loss: 0.19492416083812714\n",
      "Epoch [708/1000], Loss: 0.15926629304885864\n",
      "Epoch [709/1000], Loss: 0.34878963232040405\n",
      "Epoch [710/1000], Loss: 0.21431556344032288\n",
      "Epoch [711/1000], Loss: 0.21575582027435303\n",
      "Epoch [712/1000], Loss: 0.22578591108322144\n",
      "Epoch [713/1000], Loss: 0.19415447115898132\n",
      "Epoch [714/1000], Loss: 0.1474137008190155\n",
      "Epoch [715/1000], Loss: 0.2738262116909027\n",
      "Epoch [716/1000], Loss: 0.3770774304866791\n",
      "Epoch [717/1000], Loss: 0.2423800230026245\n",
      "Epoch [718/1000], Loss: 0.16582833230495453\n",
      "Epoch [719/1000], Loss: 0.4787063002586365\n",
      "Epoch [720/1000], Loss: 0.1961621195077896\n",
      "Epoch [721/1000], Loss: 0.22213640809059143\n",
      "Epoch [722/1000], Loss: 0.203074112534523\n",
      "Epoch [723/1000], Loss: 0.0806339755654335\n",
      "Epoch [724/1000], Loss: 0.06857697665691376\n",
      "Epoch [725/1000], Loss: 0.21195265650749207\n",
      "Epoch [726/1000], Loss: 0.13836392760276794\n",
      "Epoch [727/1000], Loss: 0.13594985008239746\n",
      "Epoch [728/1000], Loss: 0.2649906575679779\n",
      "Epoch [729/1000], Loss: 0.142171248793602\n",
      "Epoch [730/1000], Loss: 0.3742040991783142\n",
      "Epoch [731/1000], Loss: 0.07786916941404343\n",
      "Epoch [732/1000], Loss: 0.3201553225517273\n",
      "Epoch [733/1000], Loss: 0.2752005457878113\n",
      "Epoch [734/1000], Loss: 0.2184179425239563\n",
      "Epoch [735/1000], Loss: 0.18468071520328522\n",
      "Epoch [736/1000], Loss: 0.09922115504741669\n",
      "Epoch [737/1000], Loss: 0.26167112588882446\n",
      "Epoch [738/1000], Loss: 0.18058988451957703\n",
      "Epoch [739/1000], Loss: 0.3394472002983093\n",
      "Epoch [740/1000], Loss: 0.28019627928733826\n",
      "Epoch [741/1000], Loss: 0.1761840283870697\n",
      "Epoch [742/1000], Loss: 0.16156789660453796\n",
      "Epoch [743/1000], Loss: 0.3960661292076111\n",
      "Epoch [744/1000], Loss: 0.20742836594581604\n",
      "Epoch [745/1000], Loss: 0.21721164882183075\n",
      "Epoch [746/1000], Loss: 0.212824285030365\n",
      "Epoch [747/1000], Loss: 0.07742994278669357\n",
      "Epoch [748/1000], Loss: 0.31750619411468506\n",
      "Epoch [749/1000], Loss: 0.2956582009792328\n",
      "Epoch [750/1000], Loss: 0.22268952429294586\n",
      "Epoch [751/1000], Loss: 0.37513548135757446\n",
      "Epoch [752/1000], Loss: 0.21091583371162415\n",
      "Epoch [753/1000], Loss: 0.2206631898880005\n",
      "Epoch [754/1000], Loss: 0.14639410376548767\n",
      "Epoch [755/1000], Loss: 0.23831599950790405\n",
      "Epoch [756/1000], Loss: 0.14988787472248077\n",
      "Epoch [757/1000], Loss: 0.18848201632499695\n",
      "Epoch [758/1000], Loss: 0.22827406227588654\n",
      "Epoch [759/1000], Loss: 0.23768219351768494\n",
      "Epoch [760/1000], Loss: 0.1894516497850418\n",
      "Epoch [761/1000], Loss: 0.12431634217500687\n",
      "Epoch [762/1000], Loss: 0.16283182799816132\n",
      "Epoch [763/1000], Loss: 0.1577722281217575\n",
      "Epoch [764/1000], Loss: 0.1394064873456955\n",
      "Epoch [765/1000], Loss: 0.17658159136772156\n",
      "Epoch [766/1000], Loss: 0.30954042077064514\n",
      "Epoch [767/1000], Loss: 0.3185194730758667\n",
      "Epoch [768/1000], Loss: 0.1984742432832718\n",
      "Epoch [769/1000], Loss: 0.18633976578712463\n",
      "Epoch [770/1000], Loss: 0.22847454249858856\n",
      "Epoch [771/1000], Loss: 0.05365920439362526\n",
      "Epoch [772/1000], Loss: 0.26286768913269043\n",
      "Epoch [773/1000], Loss: 0.24129264056682587\n",
      "Epoch [774/1000], Loss: 0.1125498041510582\n",
      "Epoch [775/1000], Loss: 0.1801648586988449\n",
      "Epoch [776/1000], Loss: 0.16463279724121094\n",
      "Epoch [777/1000], Loss: 0.08867483586072922\n",
      "Epoch [778/1000], Loss: 0.1254241019487381\n",
      "Epoch [779/1000], Loss: 0.06012452021241188\n",
      "Epoch [780/1000], Loss: 0.46484363079071045\n",
      "Epoch [781/1000], Loss: 0.2221556454896927\n",
      "Epoch [782/1000], Loss: 0.07858186960220337\n",
      "Epoch [783/1000], Loss: 0.06801613420248032\n",
      "Epoch [784/1000], Loss: 0.38594019412994385\n",
      "Epoch [785/1000], Loss: 0.22832994163036346\n",
      "Epoch [786/1000], Loss: 0.12949946522712708\n",
      "Epoch [787/1000], Loss: 0.20192040503025055\n",
      "Epoch [788/1000], Loss: 0.23411650955677032\n",
      "Epoch [789/1000], Loss: 0.2584654688835144\n",
      "Epoch [790/1000], Loss: 0.3821300268173218\n",
      "Epoch [791/1000], Loss: 0.14942018687725067\n",
      "Epoch [792/1000], Loss: 0.19508856534957886\n",
      "Epoch [793/1000], Loss: 0.2460229992866516\n",
      "Epoch [794/1000], Loss: 0.301052451133728\n",
      "Epoch [795/1000], Loss: 0.1755572259426117\n",
      "Epoch [796/1000], Loss: 0.436882883310318\n",
      "Epoch [797/1000], Loss: 0.09722527861595154\n",
      "Epoch [798/1000], Loss: 0.18585266172885895\n",
      "Epoch [799/1000], Loss: 0.23521405458450317\n",
      "Epoch [800/1000], Loss: 0.1812410205602646\n",
      "Epoch [801/1000], Loss: 0.1445637047290802\n",
      "Epoch [802/1000], Loss: 0.29367610812187195\n",
      "Epoch [803/1000], Loss: 0.16590616106987\n",
      "Epoch [804/1000], Loss: 0.07013307511806488\n",
      "Epoch [805/1000], Loss: 0.07597194612026215\n",
      "Epoch [806/1000], Loss: 0.08089642971754074\n",
      "Epoch [807/1000], Loss: 0.17797225713729858\n",
      "Epoch [808/1000], Loss: 0.08982524275779724\n",
      "Epoch [809/1000], Loss: 0.4070518910884857\n",
      "Epoch [810/1000], Loss: 0.25461864471435547\n",
      "Epoch [811/1000], Loss: 0.32165202498435974\n",
      "Epoch [812/1000], Loss: 0.24544288218021393\n",
      "Epoch [813/1000], Loss: 0.2923838496208191\n",
      "Epoch [814/1000], Loss: 0.05634832754731178\n",
      "Epoch [815/1000], Loss: 0.1895485669374466\n",
      "Epoch [816/1000], Loss: 0.15377970039844513\n",
      "Epoch [817/1000], Loss: 0.3229725956916809\n",
      "Epoch [818/1000], Loss: 0.1287141591310501\n",
      "Epoch [819/1000], Loss: 0.09018179029226303\n",
      "Epoch [820/1000], Loss: 0.11291058361530304\n",
      "Epoch [821/1000], Loss: 0.16479060053825378\n",
      "Epoch [822/1000], Loss: 0.4275703728199005\n",
      "Epoch [823/1000], Loss: 0.060982853174209595\n",
      "Epoch [824/1000], Loss: 0.3701786398887634\n",
      "Epoch [825/1000], Loss: 0.10389574617147446\n",
      "Epoch [826/1000], Loss: 0.30761489272117615\n",
      "Epoch [827/1000], Loss: 0.26576417684555054\n",
      "Epoch [828/1000], Loss: 0.09967987984418869\n",
      "Epoch [829/1000], Loss: 0.23251810669898987\n",
      "Epoch [830/1000], Loss: 0.2165660858154297\n",
      "Epoch [831/1000], Loss: 0.3134590983390808\n",
      "Epoch [832/1000], Loss: 0.12169686704874039\n",
      "Epoch [833/1000], Loss: 0.26156073808670044\n",
      "Epoch [834/1000], Loss: 0.2382487654685974\n",
      "Epoch [835/1000], Loss: 0.2476831078529358\n",
      "Epoch [836/1000], Loss: 0.3263949453830719\n",
      "Epoch [837/1000], Loss: 0.09399210661649704\n",
      "Epoch [838/1000], Loss: 0.2108212560415268\n",
      "Epoch [839/1000], Loss: 0.43943625688552856\n",
      "Epoch [840/1000], Loss: 0.15944123268127441\n",
      "Epoch [841/1000], Loss: 0.1735679805278778\n",
      "Epoch [842/1000], Loss: 0.34066882729530334\n",
      "Epoch [843/1000], Loss: 0.14176681637763977\n",
      "Epoch [844/1000], Loss: 0.17637747526168823\n",
      "Epoch [845/1000], Loss: 0.1457984447479248\n",
      "Epoch [846/1000], Loss: 0.24723227322101593\n",
      "Epoch [847/1000], Loss: 0.2371370941400528\n",
      "Epoch [848/1000], Loss: 0.09157124906778336\n",
      "Epoch [849/1000], Loss: 0.14423619210720062\n",
      "Epoch [850/1000], Loss: 0.2697063684463501\n",
      "Epoch [851/1000], Loss: 0.42659321427345276\n",
      "Epoch [852/1000], Loss: 0.07580570876598358\n",
      "Epoch [853/1000], Loss: 0.20060625672340393\n",
      "Epoch [854/1000], Loss: 0.24351899325847626\n",
      "Epoch [855/1000], Loss: 0.30048051476478577\n",
      "Epoch [856/1000], Loss: 0.23120422661304474\n",
      "Epoch [857/1000], Loss: 0.11805637925863266\n",
      "Epoch [858/1000], Loss: 0.08597062528133392\n",
      "Epoch [859/1000], Loss: 0.1779375970363617\n",
      "Epoch [860/1000], Loss: 0.16029293835163116\n",
      "Epoch [861/1000], Loss: 0.17758041620254517\n",
      "Epoch [862/1000], Loss: 0.18228724598884583\n",
      "Epoch [863/1000], Loss: 0.1446332484483719\n",
      "Epoch [864/1000], Loss: 0.2284451276063919\n",
      "Epoch [865/1000], Loss: 0.2252669632434845\n",
      "Epoch [866/1000], Loss: 0.2695525586605072\n",
      "Epoch [867/1000], Loss: 0.2668330669403076\n",
      "Epoch [868/1000], Loss: 0.2931844890117645\n",
      "Epoch [869/1000], Loss: 0.1639396846294403\n",
      "Epoch [870/1000], Loss: 0.17543993890285492\n",
      "Epoch [871/1000], Loss: 0.2946719527244568\n",
      "Epoch [872/1000], Loss: 0.19947496056556702\n",
      "Epoch [873/1000], Loss: 0.09461857378482819\n",
      "Epoch [874/1000], Loss: 0.23416925966739655\n",
      "Epoch [875/1000], Loss: 0.10109512507915497\n",
      "Epoch [876/1000], Loss: 0.1769711673259735\n",
      "Epoch [877/1000], Loss: 0.3134251534938812\n",
      "Epoch [878/1000], Loss: 0.14102137088775635\n",
      "Epoch [879/1000], Loss: 0.325357049703598\n",
      "Epoch [880/1000], Loss: 0.13974492251873016\n",
      "Epoch [881/1000], Loss: 0.07032910734415054\n",
      "Epoch [882/1000], Loss: 0.28142887353897095\n",
      "Epoch [883/1000], Loss: 0.1751250922679901\n",
      "Epoch [884/1000], Loss: 0.13674841821193695\n",
      "Epoch [885/1000], Loss: 0.24760478734970093\n",
      "Epoch [886/1000], Loss: 0.41812214255332947\n",
      "Epoch [887/1000], Loss: 0.26740726828575134\n",
      "Epoch [888/1000], Loss: 0.1310010701417923\n",
      "Epoch [889/1000], Loss: 0.14481478929519653\n",
      "Epoch [890/1000], Loss: 0.13263535499572754\n",
      "Epoch [891/1000], Loss: 0.12124910205602646\n",
      "Epoch [892/1000], Loss: 0.2577667236328125\n",
      "Epoch [893/1000], Loss: 0.3080103397369385\n",
      "Epoch [894/1000], Loss: 0.11453170329332352\n",
      "Epoch [895/1000], Loss: 0.19034522771835327\n",
      "Epoch [896/1000], Loss: 0.26304805278778076\n",
      "Epoch [897/1000], Loss: 0.20980201661586761\n",
      "Epoch [898/1000], Loss: 0.08913158625364304\n",
      "Epoch [899/1000], Loss: 0.24180848896503448\n",
      "Epoch [900/1000], Loss: 0.2179342806339264\n",
      "Epoch [901/1000], Loss: 0.28516721725463867\n",
      "Epoch [902/1000], Loss: 0.15753944218158722\n",
      "Epoch [903/1000], Loss: 0.05686911940574646\n",
      "Epoch [904/1000], Loss: 0.2102380245923996\n",
      "Epoch [905/1000], Loss: 0.14630216360092163\n",
      "Epoch [906/1000], Loss: 0.16059397161006927\n",
      "Epoch [907/1000], Loss: 0.16100844740867615\n",
      "Epoch [908/1000], Loss: 0.055393848568201065\n",
      "Epoch [909/1000], Loss: 0.046669092029333115\n",
      "Epoch [910/1000], Loss: 0.18368229269981384\n",
      "Epoch [911/1000], Loss: 0.0490868017077446\n",
      "Epoch [912/1000], Loss: 0.24456147849559784\n",
      "Epoch [913/1000], Loss: 0.21512490510940552\n",
      "Epoch [914/1000], Loss: 0.2578679919242859\n",
      "Epoch [915/1000], Loss: 0.20161503553390503\n",
      "Epoch [916/1000], Loss: 0.07928116619586945\n",
      "Epoch [917/1000], Loss: 0.15718726813793182\n",
      "Epoch [918/1000], Loss: 0.053103554993867874\n",
      "Epoch [919/1000], Loss: 0.1794040948152542\n",
      "Epoch [920/1000], Loss: 0.18331113457679749\n",
      "Epoch [921/1000], Loss: 0.32501310110092163\n",
      "Epoch [922/1000], Loss: 0.35541805624961853\n",
      "Epoch [923/1000], Loss: 0.09009943902492523\n",
      "Epoch [924/1000], Loss: 0.09349038451910019\n",
      "Epoch [925/1000], Loss: 0.0665745884180069\n",
      "Epoch [926/1000], Loss: 0.15961824357509613\n",
      "Epoch [927/1000], Loss: 0.17767740786075592\n",
      "Epoch [928/1000], Loss: 0.20057407021522522\n",
      "Epoch [929/1000], Loss: 0.31902390718460083\n",
      "Epoch [930/1000], Loss: 0.40507546067237854\n",
      "Epoch [931/1000], Loss: 0.16159138083457947\n",
      "Epoch [932/1000], Loss: 0.20414748787879944\n",
      "Epoch [933/1000], Loss: 0.0775933563709259\n",
      "Epoch [934/1000], Loss: 0.043852128088474274\n",
      "Epoch [935/1000], Loss: 0.1994076818227768\n",
      "Epoch [936/1000], Loss: 0.23890310525894165\n",
      "Epoch [937/1000], Loss: 0.26815029978752136\n",
      "Epoch [938/1000], Loss: 0.09099605679512024\n",
      "Epoch [939/1000], Loss: 0.3339194357395172\n",
      "Epoch [940/1000], Loss: 0.04372986778616905\n",
      "Epoch [941/1000], Loss: 0.16322851181030273\n",
      "Epoch [942/1000], Loss: 0.05000258609652519\n",
      "Epoch [943/1000], Loss: 0.37590292096138\n",
      "Epoch [944/1000], Loss: 0.3187373876571655\n",
      "Epoch [945/1000], Loss: 0.15234443545341492\n",
      "Epoch [946/1000], Loss: 0.2052365094423294\n",
      "Epoch [947/1000], Loss: 0.17676503956317902\n",
      "Epoch [948/1000], Loss: 0.1862640082836151\n",
      "Epoch [949/1000], Loss: 0.15467894077301025\n",
      "Epoch [950/1000], Loss: 0.2421642243862152\n",
      "Epoch [951/1000], Loss: 0.21205145120620728\n",
      "Epoch [952/1000], Loss: 0.24008680880069733\n",
      "Epoch [953/1000], Loss: 0.2376716434955597\n",
      "Epoch [954/1000], Loss: 0.08967454731464386\n",
      "Epoch [955/1000], Loss: 0.2735765874385834\n",
      "Epoch [956/1000], Loss: 0.1445191651582718\n",
      "Epoch [957/1000], Loss: 0.15150395035743713\n",
      "Epoch [958/1000], Loss: 0.08462294191122055\n",
      "Epoch [959/1000], Loss: 0.11810315400362015\n",
      "Epoch [960/1000], Loss: 0.09460987150669098\n",
      "Epoch [961/1000], Loss: 0.08212367445230484\n",
      "Epoch [962/1000], Loss: 0.2664245367050171\n",
      "Epoch [963/1000], Loss: 0.24144452810287476\n",
      "Epoch [964/1000], Loss: 0.15956337749958038\n",
      "Epoch [965/1000], Loss: 0.08430053293704987\n",
      "Epoch [966/1000], Loss: 0.2739333212375641\n",
      "Epoch [967/1000], Loss: 0.1234489157795906\n",
      "Epoch [968/1000], Loss: 0.24481327831745148\n",
      "Epoch [969/1000], Loss: 0.12366260588169098\n",
      "Epoch [970/1000], Loss: 0.3712163269519806\n",
      "Epoch [971/1000], Loss: 0.1477167159318924\n",
      "Epoch [972/1000], Loss: 0.148029163479805\n",
      "Epoch [973/1000], Loss: 0.30791932344436646\n",
      "Epoch [974/1000], Loss: 0.2693367600440979\n",
      "Epoch [975/1000], Loss: 0.2893436849117279\n",
      "Epoch [976/1000], Loss: 0.1965905725955963\n",
      "Epoch [977/1000], Loss: 0.25194230675697327\n",
      "Epoch [978/1000], Loss: 0.09546108543872833\n",
      "Epoch [979/1000], Loss: 0.10812272876501083\n",
      "Epoch [980/1000], Loss: 0.5019056797027588\n",
      "Epoch [981/1000], Loss: 0.2315479815006256\n",
      "Epoch [982/1000], Loss: 0.2330751121044159\n",
      "Epoch [983/1000], Loss: 0.24267272651195526\n",
      "Epoch [984/1000], Loss: 0.14996367692947388\n",
      "Epoch [985/1000], Loss: 0.22558416426181793\n",
      "Epoch [986/1000], Loss: 0.2290227860212326\n",
      "Epoch [987/1000], Loss: 0.0698031559586525\n",
      "Epoch [988/1000], Loss: 0.1336570680141449\n",
      "Epoch [989/1000], Loss: 0.21470925211906433\n",
      "Epoch [990/1000], Loss: 0.16279539465904236\n",
      "Epoch [991/1000], Loss: 0.3353469967842102\n",
      "Epoch [992/1000], Loss: 0.09989578276872635\n",
      "Epoch [993/1000], Loss: 0.31240567564964294\n",
      "Epoch [994/1000], Loss: 0.2227073311805725\n",
      "Epoch [995/1000], Loss: 0.09869997948408127\n",
      "Epoch [996/1000], Loss: 0.37436097860336304\n",
      "Epoch [997/1000], Loss: 0.09092362225055695\n",
      "Epoch [998/1000], Loss: 0.17896857857704163\n",
      "Epoch [999/1000], Loss: 0.18361888825893402\n",
      "Epoch [1000/1000], Loss: 0.2978978157043457\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming you have the following numpy arrays:\n",
    "features = X_train  # shape: (num_samples, num_features)\n",
    "labels = y_train  # shape: (num_samples,)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32).to(device)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Define input size\n",
    "input_size = features.shape[1]\n",
    "\n",
    "# Create the MLP model\n",
    "model = MLPClassifier(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_features, batch_labels in dataloader:\n",
    "        # Move batch to GPU\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs.squeeze(), batch_labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# Train prediction\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    train_outputs = model(features_tensor)\n",
    "    train_predictions = torch.round(torch.sigmoid(train_outputs)).squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "# Test prediction\n",
    "test_features = X_test  # shape: (num_test_samples, num_features)\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32).to(device)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_outputs = model(test_features_tensor)\n",
    "    test_predictions = torch.round(torch.sigmoid(test_outputs)).squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.90\n",
      "recall_score: 0.24\n",
      "f1_score: 0.38\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_matrix(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.67\n",
      "recall_score: 0.15\n",
      "f1_score: 0.25\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_matrix(y_test, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
