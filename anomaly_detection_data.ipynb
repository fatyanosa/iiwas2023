{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from missingpy import MissForest\n",
    "from sklearn.impute import KNNImputer, SimpleImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "raw = pd.read_csv(\"data/nyc_taxi.csv\",low_memory=False)\n",
    "raw['timestamp'] = pd.to_datetime(raw['timestamp'])\n",
    "\n",
    "# Preview raw dataset\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The times of anomaly events.\n",
    "anomaly_points = [\n",
    "        [\n",
    "            \"2014-10-30 15:30:00.000000\",\n",
    "            \"2014-11-03 22:30:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2014-11-25 12:00:00.000000\",\n",
    "            \"2014-11-29 19:00:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2014-12-23 11:30:00.000000\",\n",
    "            \"2014-12-27 18:30:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2014-12-29 21:30:00.000000\",\n",
    "            \"2015-01-03 04:30:00.000000\"\n",
    "        ],\n",
    "        [\n",
    "            \"2015-01-24 20:30:00.000000\",\n",
    "            \"2015-01-29 03:30:00.000000\"\n",
    "        ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling: if anomaly then 1 else 0\n",
    "raw['anomaly'] = 0  # Set default values\n",
    "for start, end in anomaly_points:\n",
    "    raw.loc[((raw['timestamp'] >= start) & (raw['timestamp'] <= end)), 'anomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp\n",
    "df = pd.DataFrame()\n",
    "df['year'] = raw['timestamp'].dt.year\n",
    "df['month'] = raw['timestamp'].dt.month\n",
    "df['day'] = raw['timestamp'].dt.day\n",
    "df['hour'] = raw['timestamp'].dt.hour\n",
    "# df['minute'] = raw['timestamp'].dt.minute\n",
    "df['value'] = raw['value']\n",
    "df['anomaly'] = raw['anomaly']\n",
    "\n",
    "# delete unused dataframe\n",
    "del raw\n",
    "\n",
    "# Preview dataset\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows representing 80% of the DataFrame for training\n",
    "num_rows = int(0.8 * len(df))\n",
    "\n",
    "# Get the first 80% of the DataFrame\n",
    "df_train = df[:num_rows]\n",
    "\n",
    "# Get the remaining 20% of the DataFrame\n",
    "df_test = df[num_rows:]\n",
    "\n",
    "# delete unused dataframe\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['anomaly'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputation dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the normal and the anomaly data\n",
    "df_train_normal = df_train[df_train['anomaly'] == 0]\n",
    "df_train_anomaly = df_train[df_train['anomaly'] == 1]\n",
    "\n",
    "# Normal training data\n",
    "df_train_normal_nan = df_train_normal.copy(deep=True)\n",
    "\n",
    "# Randomly replace 10% of the normal values with nan\n",
    "num_replaced = int(0.1 * len(df_train_normal_nan))\n",
    "random_indices = np.random.choice(df_train_normal_nan.index, size=num_replaced, replace=False)\n",
    "df_train_normal_nan.loc[random_indices, 'value'] = np.nan\n",
    "\n",
    "# Anomaly training data\n",
    "df_train_anomaly_nan = df_train_anomaly.copy(deep=True)\n",
    "\n",
    "# Replace all of the anomaly values with nan\n",
    "df_train_anomaly_nan['value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "X_train_normal = df_train_normal.drop(columns=['anomaly']).to_numpy()\n",
    "X_train_normal_nan = df_train_normal_nan.drop(columns=['anomaly']).to_numpy()\n",
    "X_train_anomaly = df_train_anomaly.drop(columns=['anomaly']).to_numpy()\n",
    "X_train_anomaly_nan = df_train_anomaly_nan.drop(columns=['anomaly']).to_numpy()\n",
    "\n",
    "# y_train_normal = df_train_normal[['anomaly']].to_numpy()\n",
    "# y_train_normal_nan = df_train_normal_nan[['anomaly']].to_numpy()\n",
    "# y_train_anomaly = df_train_anomaly[['anomaly']].to_numpy()\n",
    "# y_train_anomaly_nan = df_train_anomaly_nan[['anomaly']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused dataframe\n",
    "del df_train\n",
    "del df_train_normal\n",
    "del df_train_normal_nan\n",
    "del df_train_anomaly\n",
    "del df_train_anomaly_nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the normal and the anomaly data\n",
    "df_test_normal = df_test[df_test['anomaly'] == 0]\n",
    "df_test_anomaly = df_test[df_test['anomaly'] == 1]\n",
    "\n",
    "# Normal testing data\n",
    "df_test_normal_nan = df_test_normal.copy(deep=True)\n",
    "\n",
    "# Randomly replace 10% of the normal values with nan\n",
    "num_replaced = int(0.1 * len(df_test_normal_nan))\n",
    "random_indices = np.random.choice(df_test_normal_nan.index, size=num_replaced, replace=False)\n",
    "df_test_normal_nan.loc[random_indices, 'value'] = np.nan\n",
    "\n",
    "# Anomaly testing data\n",
    "df_test_anomaly_nan = df_test_anomaly.copy(deep=True)\n",
    "\n",
    "# Randomly all of the anomaly values with nan\n",
    "df_test_anomaly_nan['value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "X_test_normal = df_test_normal.drop(columns=['anomaly']).to_numpy()\n",
    "X_test_normal_nan = df_test_normal_nan.drop(columns=['anomaly']).to_numpy()\n",
    "X_test_anomaly = df_test_anomaly.drop(columns=['anomaly']).to_numpy()\n",
    "X_test_anomaly_nan = df_test_anomaly_nan.drop(columns=['anomaly']).to_numpy()\n",
    "\n",
    "# y_test_normal = df_test_normal[['anomaly']].to_numpy()\n",
    "# y_test_normal_nan = df_test_normal_nan[['anomaly']].to_numpy()\n",
    "# y_test_anomaly = df_test_anomaly[['anomaly']].to_numpy()\n",
    "# y_test_anomaly_nan = df_test_anomaly_nan[['anomaly']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused dataframe\n",
    "del df_test\n",
    "del df_test_normal\n",
    "del df_test_normal_nan\n",
    "del df_test_anomaly\n",
    "del df_test_anomaly_nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def RMSE(original, filled):\n",
    "    score = np.sqrt(mean_squared_error(original, filled))\n",
    "    return score\n",
    "\n",
    "\n",
    "def MAE(original, filled):\n",
    "    score = mean_absolute_error(original, filled)\n",
    "    return score\n",
    "\n",
    "\n",
    "def MAPE(original, filled):\n",
    "    score = mean_absolute_percentage_error(original, filled)\n",
    "    return score\n",
    "\n",
    "\n",
    "def metric_calc(X_filled, complete_data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_complete_data = scaler.fit_transform(complete_data)\n",
    "    scaled_X_filled = scaler.fit_transform(X_filled)\n",
    "\n",
    "    rmse = RMSE(scaled_complete_data, scaled_X_filled)\n",
    "    print(\"RMSE=\", rmse)\n",
    "\n",
    "    mae = MAE(scaled_complete_data, scaled_X_filled)\n",
    "    print(\"MAE=\", mae)\n",
    "\n",
    "    mape = MAPE(scaled_complete_data, scaled_X_filled)\n",
    "    print(\"MAPE=\", mape)\n",
    "\n",
    "\n",
    "def transform_metric(imputer, X, X_nan):\n",
    "    X_filled = imputer.transform(X_nan)\n",
    "    metric_calc(X_filled, X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=4, weights=\"uniform\")\n",
    "imputer.fit(X_train_normal_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NORMAL\")\n",
    "print(\"X_train_normal\")\n",
    "transform_metric(imputer, X_train_normal, X_train_normal_nan)\n",
    "\n",
    "print(\"X_test_normal\")\n",
    "transform_metric(imputer, X_test_normal, X_test_normal_nan)\n",
    "\n",
    "print(\"\\nANOMALY\")\n",
    "print(\"X_train_anomaly\")\n",
    "transform_metric(imputer, X_train_anomaly, X_train_anomaly_nan)\n",
    "\n",
    "print(\"X_test_anomaly\")\n",
    "transform_metric(imputer, X_test_anomaly, X_test_anomaly_nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train_normal_filled = imputer.fit(X_train_normal_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NORMAL\")\n",
    "print(\"X_train_normal\")\n",
    "transform_metric(imputer, X_train_normal, X_train_normal_nan)\n",
    "\n",
    "print(\"X_test_normal\")\n",
    "transform_metric(imputer, X_test_normal, X_test_normal_nan)\n",
    "\n",
    "print(\"\\nANOMALY\")\n",
    "print(\"X_train_anomaly\")\n",
    "transform_metric(imputer, X_train_anomaly, X_train_anomaly_nan)\n",
    "\n",
    "print(\"X_test_anomaly\")\n",
    "transform_metric(imputer, X_test_anomaly, X_test_anomaly_nan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MissForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = MissForest(random_state=1337)\n",
    "X_train_normal_filled = imputer.fit(X_train_normal_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NORMAL\")\n",
    "print(\"X_train_normal\")\n",
    "transform_metric(imputer, X_train_normal, X_train_normal_nan)\n",
    "\n",
    "print(\"X_test_normal\")\n",
    "transform_metric(imputer, X_test_normal, X_test_normal_nan)\n",
    "\n",
    "print(\"\\nANOMALY\")\n",
    "print(\"X_train_anomaly\")\n",
    "# transform_metric(imputer, X_train_anomaly, X_train_anomaly_nan)\n",
    "\n",
    "print(\"X_test_anomaly\")\n",
    "transform_metric(imputer, X_test_anomaly, X_test_anomaly_nan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoimpute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
